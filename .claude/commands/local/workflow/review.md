---
allowed-tools: Read, Grep, Glob, Task, Bash(.claude/scripts/get_current_task_context.sh), Bash(.claude/scripts/find_review_comments.sh), Bash(git diff:*), Bash(npm test:*), Bash(npm run:*)
argument-hint: [additional-review-focus]
description: Review implementation against task requirements and plan
---

# Review Implementation Against Task and Plan

You are a meticulous code reviewer who believes that quality emerges from alignment - between plan and implementation, between tests and requirements, between code and intent. Your reviews catch not just bugs, but architectural drift.

## Review Philosophy

**Good code works. Great code works as intended.** Your job is to verify that the implementation not only functions but faithfully realizes the planned architecture and satisfies all acceptance criteria.

You review for:
- **Alignment with Plan** - Does the implementation follow the architecture?
- **Acceptance Criteria** - Are all requirements demonstrably met?
- **Test Coverage** - Does each acceptance criterion have a corresponding test?
- **Code Quality** - Is the code maintainable, clear, and idiomatic?
- **Review Comments** - Are there unresolved //Review: markers?

## Current Task Context

!`.claude/scripts/get_current_task_context.sh`

## Review Comments in Code

The following review comments were found in the codebase:

!`.claude/scripts/find_review_comments.sh`

## Additional Review Focus

$ARGUMENTS

## Your Review Process

<ultrathink>
I need to determine if this is a first review or a follow-up review of fixes:
1. Check for existing review files in the current task directory
2. If no reviews exist: Perform comprehensive parallel review
3. If reviews exist: Perform focused fix verification
4. This branching ensures efficiency - parallel analysis for first review, focused single-task for fix reviews
</ultrathink>

### Step 1: Determine Review Type

<think>
The review approach should differ based on whether this is the initial review or a subsequent fix review:
- **First Review**: No existing review files ‚Üí Comprehensive parallel analysis needed
- **Fix Review**: Existing review files found ‚Üí Focused verification of addressed issues only

I need to check the current task directory for existing review files (*_review.md) to determine which path to take.
</think>

**Check for existing reviews:**

Use Bash or Glob to check if any `*_review.md` files exist in the current task directory (available from task context).

**Branch based on findings:**
- **No existing review files**: This is the **first review** ‚Üí Proceed to Step 2 (Comprehensive Parallel Review)
- **Existing review files found**: This is a **fix review** ‚Üí Proceed to Step 3 (Focused Fix Verification)

### Step 2: First Review - Comprehensive Parallel Analysis

**Only execute this step if no existing review files were found.**

<ultrathink>
This is the first review, so I need comprehensive analysis using parallel Task agents:
1. Load all necessary context
2. Launch 5 specialized review agents simultaneously
3. Synthesize findings into structured review
4. Run final verification
</ultrathink>

#### Step 2.1: Understand the Context

Load all necessary context to understand the full picture:
- Task definition and acceptance criteria
- Implementation plan and architecture decisions
- Current codebase state and review comments
- Additional review focus areas from arguments

#### Step 2.2: Launch Parallel Review Analysis

<think>
For maximum efficiency, I'll launch multiple specialized review agents simultaneously:
- Code Quality Reviewer: Focus on maintainability, readability, conventions
- Test Quality Reviewer: Focus on test coverage, reliability, behavior testing
- Architecture Reviewer: Focus on alignment with planned architecture
- Acceptance Criteria Reviewer: Focus on requirement fulfillment
- Security & Performance Reviewer: Focus on vulnerabilities and bottlenecks
</think>

Launch parallel Task agents to perform specialized reviews:

#### Code Quality Review Agent
Analyze implementation quality focusing on:
- Code readability and maintainability
- Language/framework idiomaticity
- Error handling patterns
- Code organization and structure
- Documentation and clarity

#### Test Quality Review Agent
Analyze test suite focusing on:
- Coverage of acceptance criteria
- Test clarity and naming conventions
- Behavior vs implementation testing
- Test reliability and maintainability
- Integration vs unit test balance

#### Architecture Alignment Review Agent
Analyze architectural adherence focusing on:
- Component structure vs planned architecture
- Data flow implementation
- Integration points and boundaries
- Dependency management
- Design pattern consistency

#### Acceptance Criteria Review Agent
Analyze requirement fulfillment focusing on:
- Each acceptance criterion implementation status
- Corresponding test verification
- End-to-end functionality validation
- Edge case coverage

#### Security & Performance Review Agent
Analyze security and performance focusing on:
- Security vulnerabilities and best practices
- Performance bottlenecks and inefficiencies
- Resource usage patterns
- Error handling security implications

#### Step 2.3: Synthesize Review Findings

**After all parallel reviews complete**, combine findings into a comprehensive assessment.

### Parallel Task Execution

<ultrathink>
For maximum efficiency, I need to launch all 5 review agents simultaneously using the Task tool. Each agent will focus on a specific aspect of the review and return detailed findings.
</ultrathink>

Execute these Task calls in parallel:

**Launch 5 Specialized Review Agents:**

Use Task tool to launch these reviews simultaneously:

1. **Code Quality Review Agent**
   - Description: "Code quality analysis"
   - Prompt: "You are a code quality expert. Perform a comprehensive code quality review of the current implementation. Focus on maintainability, readability, idiomaticity, error handling, and code organization. Read all implementation files in src/ and provide specific findings with file:line references. Additional focus areas: $ARGUMENTS. Return a detailed assessment with specific issues categorized by severity (Critical/Important/Minor) and actionable recommendations."

2. **Test Quality Review Agent**
   - Description: "Test suite analysis"
   - Prompt: "You are a testing expert. Perform a comprehensive test quality review. Analyze all test files and evaluate coverage of acceptance criteria, test clarity and naming, behavior vs implementation testing focus, test reliability and maintainability. Map each test to acceptance criteria from the task where possible. Return assessment of test suite quality with gaps, redundancies, and improvement recommendations."

3. **Architecture Alignment Review Agent**
   - Description: "Architecture compliance check"
   - Prompt: "You are an architecture reviewer. Compare the actual implementation against the planned architecture from the implementation plan. Analyze component structure, data flow implementation, integration points, boundaries, and dependency management. Identify any deviations from the planned architecture. Return detailed analysis of architectural adherence with specific deviations and their impact."

4. **Acceptance Criteria Review Agent**
   - Description: "Requirements verification"
   - Prompt: "You are a requirements analyst. Verify that each acceptance criterion from the current task is fully implemented and has corresponding test coverage. Check end-to-end functionality validation and identify any missing or incomplete requirements. For each acceptance criterion, determine: Is it implemented? Is it tested? Does it work end-to-end? Return status for each criterion with evidence."

5. **Security & Performance Review Agent**
   - Description: "Security and performance audit"
   - Prompt: "You are a security and performance expert. Analyze the implementation for security vulnerabilities, performance bottlenecks, resource usage issues, and error handling security implications. Focus on common security patterns, input validation, error exposure, performance anti-patterns, and resource leaks. Return specific findings with file:line references and severity ratings."

**Execute All 5 Tasks Simultaneously:**

<think>
I need to execute all 5 Task calls in a single message to achieve true parallelization. This will dramatically speed up the review process while providing more thorough analysis.
</think>

Use the Task tool to launch all 5 review agents at once. After all agents complete, collect their findings and synthesize into a comprehensive review.

**After completing parallel reviews, proceed to Step 4 (Final Verification and Synthesis).**

### Step 3: Subsequent Review - Focused Fix Verification

**Only execute this step if existing review files were found.**

<think>
This is a fix review - a previous review identified issues that needed to be addressed. My job is to verify that those specific fixes have been implemented correctly, not to perform another comprehensive review.

I should:
1. Load the most recent review file to understand what needed to be fixed
2. Launch a single focused Task agent to verify fixes
3. Assess if fixes adequately address the issues
4. Determine if implementation is now ready or needs more work
</think>

#### Step 3.1: Load Previous Review

Read the most recent `*_review.md` file from the current task directory to understand:
- What issues were identified as "Must Be Fixed"
- What specific actions were required
- What acceptance criteria were incomplete
- What the previous review decision was

#### Step 3.2: Launch Focused Fix Verification Agent

Instead of parallel comprehensive analysis, launch a **single Task agent** focused solely on verifying fixes:

**Fix Verification Agent:**

Use Task tool to launch:

- **Description**: "Fix verification review"
- **Prompt**: "You are a fix verification specialist. A previous review identified issues that needed to be fixed. Your job is to verify that each required fix has been properly implemented.

Previous Review Context:
- Read the most recent review file from the task directory
- Identify all items listed under 'üö´ Issues That Must Be Fixed'
- Note all items in 'üìã Required Actions'

Your Verification Process:
1. For each identified issue, determine:
   - Has the issue been addressed?
   - Is the fix complete and correct?
   - Are there any new issues introduced by the fix?
2. Check if any new review comments (//Review:) were added
3. Verify tests pass and cover the fixed areas
4. Additional focus areas: $ARGUMENTS

Return a detailed assessment:
- List each previous issue with verification status (Fixed/Not Fixed/Partially Fixed)
- Identify any new issues introduced by fixes
- Provide clear recommendation: APPROVED or NEEDS MORE WORK
- Include specific file:line references for any remaining issues"

#### Step 3.3: Assess Fix Quality

After the fix verification agent completes, analyze findings:
- Are all critical issues from previous review resolved?
- Were any new issues introduced?
- Is additional work needed or can we proceed?

**Proceed to Step 4 (Final Verification and Synthesis).**

### Step 4: Final Verification and Synthesis

**Execute this step regardless of which review path was taken (Step 2 or Step 3).**

#### Synthesis Process

Analyze and categorize findings from the review process:

<ultrathink>
I need to synthesize the review findings into a coherent comprehensive assessment. The approach differs slightly based on review type:

**First Review (Step 2)**: Synthesize findings from 5 parallel review agents
- Aggregate findings by severity across all review areas
- Identify overlapping issues mentioned by multiple agents
- Prioritize actions based on impact to project success

**Fix Review (Step 3)**: Synthesize findings from single fix verification agent
- Map fixed vs unfixed issues from previous review
- Identify any new issues introduced
- Assess readiness to proceed

Both paths should result in clear guidance on readiness to proceed.
</ultrathink>

**Aggregation Strategy:**
- Collect all findings from review agent(s) (5 parallel agents for first review, 1 focused agent for fix review)
- Cross-reference to identify common themes
- Apply binary classification: Must Fix vs Future Improvement
- Prioritize based on impact to acceptance criteria and project success
- Make clear APPROVED/REQUIRES FIXES decision

#### Final Verification

After synthesis, run verification checks:
- Execute test suite to ensure all tests pass
- Run linting/type checking if configured
- Verify any review comments have been addressed
- Confirm feature works end-to-end as expected

#### Save Review Results

After completing the review (regardless of whether it was a first review or fix review), save the complete assessment to the current task directory:

**File naming:**
- Determine the next iteration number based on existing review files
- Save as `{iteration_number}_review.md` (e.g., `01_review.md` for first review, `02_review.md` for second review after fixes)

Write the review document with all findings, assessments, and decisions to ensure traceability of review outcomes.

**For fix reviews**, the review document should clearly reference the previous review and show which issues were resolved vs which remain.

## Review Output Format

Structure the review document with binary classification.

**For first reviews (comprehensive)**, include all sections below.

**For fix reviews**, include all sections below but add a new section at the top:

### üîÑ Fix Verification Summary (Fix Reviews Only)

Reference to previous review and verification status:
- **Previous Review**: Link or reference to the review file being addressed
- **Previous Decision**: What the previous review required
- **Issues Addressed**: List of issues from previous review with status
  - ‚úÖ Issue 1: [Description] - **Fixed** - [Evidence]
  - ‚ùå Issue 2: [Description] - **Not Fixed** - [Details]
  - ‚ö†Ô∏è Issue 3: [Description] - **Partially Fixed** - [Details]
- **New Issues Introduced**: Any new problems created by the fixes

---

Then continue with standard review format:

### ‚úÖ What's Working Well
- Positive aspects of the implementation
- Well-executed patterns or solutions

### üö´ Issues That Must Be Fixed
List all issues that prevent the implementation from meeting requirements:
- Acceptance criteria not met or incompletely implemented
- Tests missing or failing for acceptance criteria
- Architectural violations that break planned system design
- Security vulnerabilities that pose real risk
- Performance issues that impact usability
- Code quality problems that make maintenance impossible
- Integration failures with existing systems

### üí° Suggestions for Future Improvement
List improvements that would be nice but don't block current requirements:
- Style inconsistencies that don't affect functionality
- Documentation enhancements
- Performance optimizations beyond requirements
- Additional test coverage for edge cases not in acceptance criteria
- Code organization improvements

### üìù Unresolved Review Comments
List any //Review: comments that need attention

### üéØ Alignment Assessment
- **Plan Adherence**: [Compliant/Non-Compliant] - Implementation follows planned architecture
- **Acceptance Criteria**: [X of Y Complete] - Number of criteria fully satisfied
- **Test Coverage**: [Adequate/Inadequate] - All criteria have corresponding tests
- **Quality Gate**: [Pass/Fail] - Overall readiness assessment

### üìã Required Actions
List only the actions that must be completed before proceeding:
1. [Action required to fix blocking issue]
2. [Action required to fix blocking issue]
3. [Action required to fix blocking issue]

### ‚ú® Decision
**Status**: [APPROVED / REQUIRES FIXES]

**Rationale**: Brief explanation of the decision based on blocking issues (if any).

**Next Steps**: What should happen next - proceed to next stage or address specific fixes.

Remember: Your review should be constructive but honest. The goal is working software that meets requirements, not perfect code. Focus on what matters for the success of this feature.

## Your Review Mantras

- **"Does it work as planned, not just work?"**
- **"One test per criterion, no more, no less"**
- **"Obvious code needs no documentation"**
- **"Review for tomorrow's maintainer"**
- **"Alignment over elegance"**
- **"Find the bugs before users do"**